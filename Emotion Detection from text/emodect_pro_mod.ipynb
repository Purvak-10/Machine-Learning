{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\purva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\purva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data read\n",
    "df=pd.read_csv(\"isear_processed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>during the period of falling in love each time...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i was involved in a traffic accident</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when i was driving home after several days of ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when i lost the person who meant the most to me</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the time i knocked a deer down the sight of th...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>two years back someone invited me to be the tu...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>i had taken the responsibility to do something...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>i was at home and i heard a loud sound of spit...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>i did not do the homework that the teacher had...</td>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>i had shouted at my younger brother and he was...</td>\n",
       "      <td>guilt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text   labels\n",
       "0     during the period of falling in love each time...      joy\n",
       "1             when i was involved in a traffic accident     fear\n",
       "2     when i was driving home after several days of ...    anger\n",
       "3       when i lost the person who meant the most to me  sadness\n",
       "4     the time i knocked a deer down the sight of th...  disgust\n",
       "...                                                 ...      ...\n",
       "7661  two years back someone invited me to be the tu...    anger\n",
       "7662  i had taken the responsibility to do something...  sadness\n",
       "7663  i was at home and i heard a loud sound of spit...  disgust\n",
       "7664  i did not do the homework that the teacher had...    shame\n",
       "7665  i had shouted at my younger brother and he was...    guilt\n",
       "\n",
       "[7666 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>during the period of falling in love each time...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i was involved in a traffic accident</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when i was driving home after several days of ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when i lost the person who meant the most to me</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the time i knocked a deer down the sight of th...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>two years back someone invited me to be the tu...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>i had taken the responsibility to do something...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>i was at home and i heard a loud sound of spit...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>i did not do the homework that the teacher had...</td>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>i had shouted at my younger brother and he was...</td>\n",
       "      <td>guilt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text   labels\n",
       "0     during the period of falling in love each time...      joy\n",
       "1             when i was involved in a traffic accident     fear\n",
       "2     when i was driving home after several days of ...    anger\n",
       "3       when i lost the person who meant the most to me  sadness\n",
       "4     the time i knocked a deer down the sight of th...  disgust\n",
       "...                                                 ...      ...\n",
       "7661  two years back someone invited me to be the tu...    anger\n",
       "7662  i had taken the responsibility to do something...  sadness\n",
       "7663  i was at home and i heard a loud sound of spit...  disgust\n",
       "7664  i did not do the homework that the teacher had...    shame\n",
       "7665  i had shouted at my younger brother and he was...    guilt\n",
       "\n",
       "[7513 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if there are null values in the dataset\n",
    "df=df[~(df['cleaned_text'].isnull())]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "- Tokenization: Splitting the text into individual words or tokens\n",
    "- Lemmatization: Reducing words to their base form\n",
    "- Stop Word Removal: Removing Stop words that are not useful for training, eg: the, is, and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize_remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]  # Lemmatization and stop words removal\n",
    "\n",
    "    return ' '.join(tokens)  # Join tokens into string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the tokenize_lemmatize_remove_stopwords() function to the 'cleaned_text' column\n",
    "df['processed_text'] = df['cleaned_text'].apply(tokenize_lemmatize_remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>during the period of falling in love each time...</td>\n",
       "      <td>joy</td>\n",
       "      <td>period falling love time met especially met lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i was involved in a traffic accident</td>\n",
       "      <td>fear</td>\n",
       "      <td>involved traffic accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when i was driving home after several days of ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>driving home several day hard work motorist ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when i lost the person who meant the most to me</td>\n",
       "      <td>sadness</td>\n",
       "      <td>lost person meant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the time i knocked a deer down the sight of th...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>time knocked deer sight animal injury helpless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>two years back someone invited me to be the tu...</td>\n",
       "      <td>anger</td>\n",
       "      <td>two year back someone invited tutor granddaugh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>i had taken the responsibility to do something...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>taken responsibility something prepared howeve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>i was at home and i heard a loud sound of spit...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>home heard loud sound spitting outside door th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>i did not do the homework that the teacher had...</td>\n",
       "      <td>shame</td>\n",
       "      <td>homework teacher asked u scolded immediately</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>i had shouted at my younger brother and he was...</td>\n",
       "      <td>guilt</td>\n",
       "      <td>shouted younger brother always afraid called l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7513 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text   labels  \\\n",
       "0     during the period of falling in love each time...      joy   \n",
       "1             when i was involved in a traffic accident     fear   \n",
       "2     when i was driving home after several days of ...    anger   \n",
       "3       when i lost the person who meant the most to me  sadness   \n",
       "4     the time i knocked a deer down the sight of th...  disgust   \n",
       "...                                                 ...      ...   \n",
       "7661  two years back someone invited me to be the tu...    anger   \n",
       "7662  i had taken the responsibility to do something...  sadness   \n",
       "7663  i was at home and i heard a loud sound of spit...  disgust   \n",
       "7664  i did not do the homework that the teacher had...    shame   \n",
       "7665  i had shouted at my younger brother and he was...    guilt   \n",
       "\n",
       "                                         processed_text  \n",
       "0     period falling love time met especially met lo...  \n",
       "1                             involved traffic accident  \n",
       "2     driving home several day hard work motorist ah...  \n",
       "3                                     lost person meant  \n",
       "4     time knocked deer sight animal injury helpless...  \n",
       "...                                                 ...  \n",
       "7661  two year back someone invited tutor granddaugh...  \n",
       "7662  taken responsibility something prepared howeve...  \n",
       "7663  home heard loud sound spitting outside door th...  \n",
       "7664       homework teacher asked u scolded immediately  \n",
       "7665  shouted younger brother always afraid called l...  \n",
       "\n",
       "[7513 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"text\"]=df[\"processed_text\"]\n",
    "new_df[\"labels\"]=df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>period falling love time met especially met lo...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>involved traffic accident</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>driving home several day hard work motorist ah...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lost person meant</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time knocked deer sight animal injury helpless...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>two year back someone invited tutor granddaugh...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>taken responsibility something prepared howeve...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>home heard loud sound spitting outside door th...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>homework teacher asked u scolded immediately</td>\n",
       "      <td>shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>shouted younger brother always afraid called l...</td>\n",
       "      <td>guilt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   labels\n",
       "0     period falling love time met especially met lo...      joy\n",
       "1                             involved traffic accident     fear\n",
       "2     driving home several day hard work motorist ah...    anger\n",
       "3                                     lost person meant  sadness\n",
       "4     time knocked deer sight animal injury helpless...  disgust\n",
       "...                                                 ...      ...\n",
       "7661  two year back someone invited tutor granddaugh...    anger\n",
       "7662  taken responsibility something prepared howeve...  sadness\n",
       "7663  home heard loud sound spitting outside door th...  disgust\n",
       "7664       homework teacher asked u scolded immediately    shame\n",
       "7665  shouted younger brother always afraid called l...    guilt\n",
       "\n",
       "[7513 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.get_dummies(new_df, columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels_anger</th>\n",
       "      <th>labels_disgust</th>\n",
       "      <th>labels_fear</th>\n",
       "      <th>labels_guilt</th>\n",
       "      <th>labels_joy</th>\n",
       "      <th>labels_sadness</th>\n",
       "      <th>labels_shame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>period falling love time met especially met lo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>involved traffic accident</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>driving home several day hard work motorist ah...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lost person meant</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time knocked deer sight animal injury helpless...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>two year back someone invited tutor granddaugh...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>taken responsibility something prepared howeve...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>home heard loud sound spitting outside door th...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>homework teacher asked u scolded immediately</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>shouted younger brother always afraid called l...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7513 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels_anger  \\\n",
       "0     period falling love time met especially met lo...         False   \n",
       "1                             involved traffic accident         False   \n",
       "2     driving home several day hard work motorist ah...          True   \n",
       "3                                     lost person meant         False   \n",
       "4     time knocked deer sight animal injury helpless...         False   \n",
       "...                                                 ...           ...   \n",
       "7661  two year back someone invited tutor granddaugh...          True   \n",
       "7662  taken responsibility something prepared howeve...         False   \n",
       "7663  home heard loud sound spitting outside door th...         False   \n",
       "7664       homework teacher asked u scolded immediately         False   \n",
       "7665  shouted younger brother always afraid called l...         False   \n",
       "\n",
       "      labels_disgust  labels_fear  labels_guilt  labels_joy  labels_sadness  \\\n",
       "0              False        False         False        True           False   \n",
       "1              False         True         False       False           False   \n",
       "2              False        False         False       False           False   \n",
       "3              False        False         False       False            True   \n",
       "4               True        False         False       False           False   \n",
       "...              ...          ...           ...         ...             ...   \n",
       "7661           False        False         False       False           False   \n",
       "7662           False        False         False       False            True   \n",
       "7663            True        False         False       False           False   \n",
       "7664           False        False         False       False           False   \n",
       "7665           False        False          True       False           False   \n",
       "\n",
       "      labels_shame  \n",
       "0            False  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  \n",
       "...            ...  \n",
       "7661         False  \n",
       "7662         False  \n",
       "7663         False  \n",
       "7664          True  \n",
       "7665         False  \n",
       "\n",
       "[7513 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for model training: Splitting,Tokenization, Encoding and Label extraction\n",
    "- Splitting the data\n",
    "    Train size: 80%, Test size: 10%, Validation size: 10%\n",
    "- Tokenization \n",
    "- Encoding: The tokenized text data is transformed into tensors. The \"input_ids\" represent the tokenized words, and the \"attention_mask\" indicates which tokens should be attended to or ignored (e.g., padding tokens)\n",
    "- Label Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(new_df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "train_encoded = tokenizer(train_df['text'].tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "val_encoded = tokenizer(val_df['text'].tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "test_encoded = tokenizer(test_df['text'].tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "train_inputs = {'input_ids': train_encoded['input_ids'], 'attention_mask': train_encoded['attention_mask']}\n",
    "val_inputs = {'input_ids': val_encoded['input_ids'], 'attention_mask': val_encoded['attention_mask']}\n",
    "test_inputs = {'input_ids': test_encoded['input_ids'], 'attention_mask': test_encoded['attention_mask']}\n",
    "\n",
    "train_labels = np.array(train_df.iloc[:, 1:])  \n",
    "val_labels = np.array(val_df.iloc[:, 1:])\n",
    "test_labels = np.array(test_df.iloc[:, 1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6010, 8), (752, 8), (751, 8), (6010, 7), (752, 7), (751, 7))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape, val_df.shape, train_labels.shape, test_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels)).batch(32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_inputs, val_labels)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_inputs, test_labels)).batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs:\n",
      " [[    0 41642   213 ...     1     1     1]\n",
      " [    0  1208 13356 ...     1     1     1]\n",
      " [    0  1397  1291 ...     1     1     1]\n",
      " ...\n",
      " [    0 19010  5537 ...     1     1     1]\n",
      " [    0 31828   428 ...     1     1     1]\n",
      " [    0 37945 24320 ...     1     1     1]]\n",
      "Attention Mask:\n",
      " [[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Print one batch of the dataset \n",
    "for batch in train_dataset:\n",
    "    input_ids = batch[0]['input_ids']\n",
    "    attention_mask = batch[0]['attention_mask']\n",
    "    \n",
    "    print(\"Input IDs:\\n\", input_ids.numpy())\n",
    "    print(\"Attention Mask:\\n\", attention_mask.numpy())\n",
    "    break  # After printing one batch break from the loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ...,  True, False, False],\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 83), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 83), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, 7), dtype=tf.bool, name=None))>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta-bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.embeddings.position_ids', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_roberta_model_1 (TFRobe  TFBaseModelOutputWithPooli   1246456   ['input_ids[0][0]',           \n",
      " rtaModel)                   ngAndCrossAttentions(last_   32         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, None,                                            \n",
      "                             768),                                                                \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 256)                  918528    ['tf_roberta_model_1[0][0]']  \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  32896     ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)        (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 7)                    903       ['dropout_74[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125597959 (479.12 MB)\n",
      "Trainable params: 125597959 (479.12 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    roberta_output = roberta_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    \n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=False))(roberta_output)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    output = tf.keras.layers.Dense(7, activation='softmax')(x) \n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\purva\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:From C:\\Users\\purva\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "384/384 [==============================] - 2390s 6s/step - loss: 0.3810 - accuracy: 0.3294 - val_loss: 0.2790 - val_accuracy: 0.5867\n",
      "Epoch 2/3\n",
      "384/384 [==============================] - 2336s 6s/step - loss: 0.2729 - accuracy: 0.6049 - val_loss: 0.2488 - val_accuracy: 0.6167\n",
      "Epoch 3/3\n",
      "384/384 [==============================] - 2341s 6s/step - loss: 0.2298 - accuracy: 0.6693 - val_loss: 0.2388 - val_accuracy: 0.6271\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 48s 884ms/step - loss: 0.2301 - accuracy: 0.6714\n",
      "Test Loss: 0.23011678457260132\n",
      "Test Accuracy: 0.671447217464447\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_roberta_model_1 (TFRobe  TFBaseModelOutputWithPooli   1246456   ['input_ids[0][0]',           \n",
      " rtaModel)                   ngAndCrossAttentions(last_   32         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, None,                                            \n",
      "                             768),                                                                \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 128)                  459264    ['tf_roberta_model_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  16512     ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)        (None, 128)                  0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 300)                  38700     ['dropout_76[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)        (None, 300)                  0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 7)                    2107      ['dropout_77[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125162215 (477.46 MB)\n",
      "Trainable params: 125162215 (477.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    roberta_output = roberta_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    \n",
    "    x = tf.keras.layers.LSTM(128, return_sequences=False)(roberta_output)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(300, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    output = tf.keras.layers.Dense(7, activation='softmax')(x) \n",
    "    \n",
    "    model_l = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    model_l.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model_l\n",
    "\n",
    "model_l = create_model()\n",
    "model_l.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\purva\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:From C:\\Users\\purva\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "384/384 [==============================] - 2500s 6s/step - loss: 0.4318 - accuracy: 0.1833 - val_loss: 0.3531 - val_accuracy: 0.4720\n",
      "Epoch 2/3\n",
      "384/384 [==============================] - 2346s 6s/step - loss: 0.3379 - accuracy: 0.4876 - val_loss: 0.2897 - val_accuracy: 0.5776\n",
      "Epoch 3/3\n",
      "384/384 [==============================] - 2318s 6s/step - loss: 0.2843 - accuracy: 0.6027 - val_loss: 0.2717 - val_accuracy: 0.5971\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "history_l = model_l.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 46s 874ms/step - loss: 0.2569 - accuracy: 0.6323\n",
      "Test Loss: 0.25692036747932434\n",
      "Test Accuracy: 0.6323337554931641\n"
     ]
    }
   ],
   "source": [
    "test_loss_l, test_accuracy_l = model_l.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss_l}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_l}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta-gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\purva\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobert  TFBaseModelOutputWithPooli   1246456   ['input_ids[0][0]',           \n",
      " aModel)                     ngAndCrossAttentions(last_   32         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, None,                                            \n",
      "                             768),                                                                \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " gru (GRU)                   (None, 128)                  344832    ['tf_roberta_model[0][0]']    \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  16512     ['gru[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 7)                    903       ['dropout_37[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125007879 (476.87 MB)\n",
      "Trainable params: 125007879 (476.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model_gr():\n",
    "    roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    roberta_output = roberta_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    \n",
    "    x = tf.keras.layers.GRU(128, return_sequences=False)(roberta_output)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    output = tf.keras.layers.Dense(7, activation='softmax')(x) \n",
    "    \n",
    "    model_gr = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    model_gr.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model_gr\n",
    "\n",
    "model_gr = create_model_gr()\n",
    "model_gr.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\purva\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:From C:\\Users\\purva\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "376/376 [==============================] - 2306s 6s/step - loss: 1.3944 - accuracy: 0.4877 - val_loss: 1.1216 - val_accuracy: 0.6178\n",
      "Epoch 2/3\n",
      "376/376 [==============================] - 2273s 6s/step - loss: 0.9730 - accuracy: 0.6639 - val_loss: 1.0834 - val_accuracy: 0.6405\n",
      "Epoch 3/3\n",
      "376/376 [==============================] - 2297s 6s/step - loss: 0.7933 - accuracy: 0.7328 - val_loss: 1.1316 - val_accuracy: 0.6538\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "history_gr = model_gr.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 62s 1s/step - loss: 1.1445 - accuracy: 0.6503\n",
      "Test Loss: 1.1445326805114746\n",
      "Test Accuracy: 0.6502659320831299\n"
     ]
    }
   ],
   "source": [
    "test_loss_gr, test_accuracy_gr = model_gr.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss_gr}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_gr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
